{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcd174b3-9cb2-47ba-a0d7-7a00ceda26e7",
   "metadata": {},
   "source": [
    "# Anomaly Detections using recursive Tree search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37f3a59-ed7b-466b-adeb-48b98cb1ae5f",
   "metadata": {},
   "source": [
    "### Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "294ba915-23d1-4730-b0fd-71cedf6a414d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Union\n",
    "\n",
    "import pandas as pd\n",
    "import btrdb\n",
    "from btrdb.stream import Stream\n",
    "\n",
    "from btrdb.utils.general import pointwidth\n",
    "from btrdb.utils.timez import ns_to_datetime, to_nanoseconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051be7d4-7707-412d-a63a-d15a2421cdaf",
   "metadata": {},
   "source": [
    "Helper function to join timestamps/windows that have previous end the same consecutive start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58922c89-366c-41a4-b72f-37eb4e1dc473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_consecutive_windows(\n",
    "    dataframe,\n",
    "    event_merge_threshold_ns: int = 0,\n",
    "    agg: str = \"max\",\n",
    "    data_columns: str = \"Severity\",\n",
    "    stream=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Combine consecutive windows (end time is the same as the consecutive start time) into a single timerange.\n",
    "    Such as [(2021-03-15 18:34:54.518091776,\t2021-03-15 18:35:03.108026368),\n",
    "    (2021-03-15 18:35:03.108026368,\t2021-03-15 18:35:11.697960960)]\n",
    "    -> [(2021-03-15 18:34:54.518091776,\t2021-03-15 18:35:11.697960960)].\n",
    "\n",
    "    If a stream object is given, check for the gaps between the events and combine the windows.\n",
    "\n",
    "    NOTE: DataFrame must have [\"StartTime\", \"EndTime\"], error will be thrown if not in the columns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe : DataFrame\n",
    "        A Pandas' DataFrame object.\n",
    "    event_merge_threshold_ns : int\n",
    "        If 2 events are within the specified time range in nanoseconds (end of previous event to start of consecutive),\n",
    "        they are combined as a single event.\n",
    "    agg : str\n",
    "        Aggregation function to apply to the 'Severity'.\n",
    "    data_columns : str or list of str\n",
    "        Column names to apply aggregation to.\n",
    "    stream : Stream, optional\n",
    "        Stream to check for gaps between the events and combine the event windows.\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        A Pandas' DataFrame object\n",
    "    \"\"\"\n",
    "\n",
    "    def _agg_data_columns(data, mask, starttimes, end_times):\n",
    "        \"\"\"\n",
    "        Apply aggregation to the given `data_columns`.\n",
    "        \"\"\"\n",
    "        severity = (\n",
    "            data[data_columns].where(mask).copy()  # use the starttime as reference\n",
    "        )\n",
    "        for startidx, endidx in zip(*[starttimes.index, end_times.index]):\n",
    "            severity[startidx] = data.loc[startidx:endidx, data_columns].agg(agg)\n",
    "        return severity.dropna()\n",
    "\n",
    "    # DataFrame must have [\"StartTime\", \"EndTime\"], error will be thrown if not in columns\n",
    "    merge_endtimes = dataframe.EndTime[\n",
    "        (dataframe.StartTime.shift(-1) - dataframe.EndTime > event_merge_threshold_ns)\n",
    "        | dataframe.StartTime.shift(-1).isna()\n",
    "    ]\n",
    "    merge_starttimes = dataframe.StartTime[\n",
    "        (dataframe.StartTime - dataframe.EndTime.shift(1) > event_merge_threshold_ns)\n",
    "        | dataframe.EndTime.shift(1).isna()\n",
    "    ]\n",
    "    if len(merge_endtimes) != len(merge_starttimes):\n",
    "        warnings.warn(\"Unequal sizes for the merging start and end times.\")\n",
    "    elif len(merge_endtimes) == 0 or len(merge_starttimes) == 0:\n",
    "        # nothing to merge\n",
    "        return dataframe\n",
    "    severity = _agg_data_columns(\n",
    "        dataframe,\n",
    "        dataframe.StartTime - dataframe.EndTime.shift(1) > event_merge_threshold_ns,\n",
    "        merge_starttimes,\n",
    "        merge_endtimes,\n",
    "    )\n",
    "\n",
    "    merged_df = pd.concat(\n",
    "        [\n",
    "            merge_starttimes.reset_index(drop=True),\n",
    "            merge_endtimes.reset_index(drop=True),\n",
    "            severity.reset_index(drop=True),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    if stream is not None and merged_df.shape[0] > 1:\n",
    "        # combine the windows between the events if gaps (if the count == 0)\n",
    "        # (done after merging to reduce the number of events)\n",
    "        count = pd.concat(\n",
    "            [\n",
    "                merged_df.EndTime,\n",
    "                merged_df.StartTime.shift(-1),\n",
    "            ],\n",
    "            axis=1,\n",
    "        ).apply(\n",
    "            lambda x: stream.count(int(x.EndTime), int(x.StartTime), precise=True)\n",
    "            if not x.isna().any()\n",
    "            else None,\n",
    "            axis=1,\n",
    "        )\n",
    "\n",
    "        merged_start = merged_df.StartTime[~count.shift(1).eq(0) | count.isna()]\n",
    "        merged_end = merged_df.EndTime[~count.eq(0) | count.isna()]\n",
    "        severity = _agg_data_columns(\n",
    "            merged_df, ~count.shift(1).eq(0) | count.isna(), merged_start, merged_end\n",
    "        )\n",
    "\n",
    "        merged_df = pd.concat(\n",
    "            [\n",
    "                merged_start.reset_index(drop=True),\n",
    "                merged_end.reset_index(drop=True),\n",
    "                severity.reset_index(drop=True),\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "def search_generator_to_dataframe(search_generator):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    search_generator : generator\n",
    "        The search_generator object containing the search results.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : DataFrame\n",
    "        The DataFrame containing the search results. The columns of the DataFrame depend on the\n",
    "        shape of the search_generator object. If it has only one column, the column name will be\n",
    "        \"Time\". If it has two columns, the column names will be \"StartTime\" and \"EndTime\".\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(search_generator)\n",
    "    if df.shape[1] == 1:\n",
    "        df.columns = [\"Time\"]\n",
    "    elif df.shape[1] == 2:\n",
    "        df.columns = [\"StartTime\", \"EndTime\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdc01da-f167-447e-b57b-8b647c2f4eda",
   "metadata": {},
   "source": [
    "#### Get a stream to search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4529bc6-52c7-4bd3-8920-fa02487f96af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UUID('d60fc469-a6da-4c98-8763-fd833293d955')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = btrdb.connect()\n",
    "streams = conn.streams_in_collection(\"sunshine\", tags={\"unit\": \"volts\"})\n",
    "stream = streams[0]\n",
    "stream.uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9582ace8-389e-4136-b187-b2f8ab3c20cc",
   "metadata": {},
   "source": [
    "#### Initializing the start, end, and pointwidth:\n",
    "\n",
    "In this example, the pointwidth is ~13 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81a18c56-a0ba-4e83-a14c-00695a92919c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1456790400008333000, 1464738830333333000, 13.03124892178963)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = stream.earliest()[0].time\n",
    "end = stream.latest()[0].time\n",
    "initial_pw: int = pointwidth.from_nanoseconds(end - start) - 2\n",
    "version = 0\n",
    "start, end, initial_pw.days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6067db23-609d-40cc-b25f-e05cabe75f32",
   "metadata": {},
   "source": [
    "## Finding Specific Values Using Anomaly Detection\n",
    "We suggest to use this value search for values that are on the edges of the measurement distribution to not touch all of the RawPoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98727da7-dcad-4b6b-8ad4-91503dd025a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_timestamps_within_bounds(\n",
    "    stream: Stream,\n",
    "    start: int,\n",
    "    end: int,\n",
    "    bounds: Tuple[float, float],\n",
    "    initial_pw: Union[int, pointwidth] = 49,\n",
    "    final_pw: int = 36,\n",
    "    return_rawpoint_timestamps: bool = False,\n",
    "    version: int = 0,\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Find timestamps in stream between `start` and `end` that are within specified bounds values\n",
    "    (lower and upper bounds) using StatPoints recursively through BTrDB tree.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    stream: Stream\n",
    "        BTrDB Stream to search.\n",
    "    start: int\n",
    "        The start time in nanoseconds for the range to search from.\n",
    "    end: int\n",
    "        The end time in nanoseconds for the range to search from.\n",
    "    bounds: tuple(float, float), length: 2\n",
    "        Find events with values within the specified (lower, upper) bounds threshold.\n",
    "    initial_pw: int or pointwidth, default: 49\n",
    "        Initial query pointwidth of tree traversal, Default is 49 (approximately 7 days).\n",
    "    final_pw: int, default: 36\n",
    "        Final pointwidth depth to use tree traversal with StatPoints and to\n",
    "        search with RawPoints. Default is 36 (approximately 1.15 minutes).\n",
    "    return_rawpoint_timestamps: bool, default: False\n",
    "        Return RawPoint timestamps if `True`, else returns time-range tuple of start and end\n",
    "        timestamps of the StatPoint windows that is within the specified bounds threshold.\n",
    "    version: int, default: 0\n",
    "        Version of the stream to search from.\n",
    "\n",
    "    Yields\n",
    "    ------\n",
    "    tuple\n",
    "        Timestamp (nanoseconds) of start (and end if within bounds for more than specified max\n",
    "        depth default is ~1.15 minutes) timestamps of event.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    For measurement stream with values (280-290):\n",
    "\n",
    "    >>> result = search_timestamps_outside_bounds(stream, start, end, bounds=(0, 1))\n",
    "    >>> result_timestamps = [timestamp for timestamp in result]\n",
    "    >>> print(result_timestamps)\n",
    "    []\n",
    "\n",
    "    \"\"\"\n",
    "    # TODO: add more examples cases\n",
    "    assert len(bounds) == 2, \"Requires a minimum and maximum for the `bounds`\"\n",
    "    lower_bound, upper_bound = bounds\n",
    "    assert isinstance(\n",
    "        initial_pw, (int, pointwidth)\n",
    "    ), \"Please provide `initial_pw` as an integer or pointwidth object\"\n",
    "    if isinstance(initial_pw, int):\n",
    "        initial_pw = pointwidth(\n",
    "            initial_pw\n",
    "        )  # convert initial_pw integer to pointwidth object\n",
    "    windows = stream.arrow_aligned_windows(\n",
    "        start, end, int(initial_pw), version\n",
    "    ).to_pylist()\n",
    "    for window in windows:\n",
    "        # Get the time range of the current window\n",
    "        wstart = window[\"time\"]\n",
    "        wend = wstart + pd.Timedelta(initial_pw.nanoseconds, unit=\"ns\")\n",
    "\n",
    "        # if the aggregates are with the bounds, return full window\n",
    "        if not return_rawpoint_timestamps and (\n",
    "            lower_bound <= window[\"min\"] and window[\"max\"] <= upper_bound\n",
    "        ):\n",
    "            yield wstart, wend\n",
    "        elif not (window[\"max\"] < lower_bound or window[\"min\"] > upper_bound):\n",
    "            # If we are at a window length of a final_pw, use values\n",
    "            if initial_pw <= final_pw and not return_rawpoint_timestamps:\n",
    "                points = []\n",
    "                yield wstart, wend\n",
    "            elif initial_pw <= final_pw and return_rawpoint_timestamps:\n",
    "                points = stream.arrow_values(wstart, wend, version).to_pylist()\n",
    "            # Otherwise, traverse the stat point children of this node\n",
    "            else:\n",
    "                points = search_timestamps_within_bounds(\n",
    "                    stream,\n",
    "                    wstart.value,\n",
    "                    wend.value,\n",
    "                    bounds,\n",
    "                    initial_pw - 2,\n",
    "                    final_pw,\n",
    "                    return_rawpoint_timestamps=return_rawpoint_timestamps,\n",
    "                    version=version,\n",
    "                )\n",
    "\n",
    "            for point in points:\n",
    "                if isinstance(point, dict):\n",
    "                    if lower_bound <= point[\"value\"] <= upper_bound:\n",
    "                        yield (point[\"time\"],)\n",
    "                else:\n",
    "                    yield point\n",
    "\n",
    "\n",
    "def search_timestamps_at_value(\n",
    "    stream: Stream,\n",
    "    start: int,\n",
    "    end: int,\n",
    "    value: Union[int, float],\n",
    "    tol: float = 1e-6,\n",
    "    initial_pw: Union[int, pointwidth] = 49,\n",
    "    final_pw: int = 36,\n",
    "    return_rawpoint_timestamps: bool = False,\n",
    "    version: int = 0,\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Find points in stream between `start` and `end` that are equal to specified values (with\n",
    "    tolerance) using StatPoints recursively through BTrDB tree.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    stream: Stream\n",
    "        BTrDB Stream to search.\n",
    "    start: int\n",
    "        The start time in nanoseconds for the range to search from.\n",
    "    end: int\n",
    "        The end time in nanoseconds for the range to search from.\n",
    "    value : int, float\n",
    "        The values to search in the tree.\n",
    "    initial_pw: int or pointwidth, default: 49\n",
    "        Initial query pointwidth of tree traversal, Default is 49 (approximately 7 days).\n",
    "    final_pw: int, default: 36\n",
    "        Final pointwidth depth to use tree traversal with StatPoints and to\n",
    "        search with RawPoints. Default is 36 (approximately 1.15 minutes).\n",
    "    return_rawpoint_timestamps: bool, default: False\n",
    "        Return RawPoint timestamps if `True`, else returns time-range tuple of start and end\n",
    "        timestamps of the StatPoint windows that is outside the specified bounds threshold.\n",
    "    version: int, default: 0\n",
    "        Version of the stream to search from.\n",
    "\n",
    "    Yields\n",
    "    ------\n",
    "    tuple\n",
    "        Timestamp (nanoseconds) of start (and end if above threshold for more than specified max\n",
    "        depth default is ~1.15 minutes) timestamps of event.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> result = search_timestamps_at_value(stream, start, end, value)\n",
    "    >>> result_timestamps = [timestamp for timestamp in result]\n",
    "    >>> print(result_timestamps)\n",
    "    \"\"\"\n",
    "    # TODO: add more examples cases\n",
    "    bounds = (value - tol, value + tol)\n",
    "    yield from search_timestamps_within_bounds(\n",
    "        stream,\n",
    "        start,\n",
    "        end,\n",
    "        bounds,\n",
    "        initial_pw - 2,\n",
    "        final_pw,\n",
    "        return_rawpoint_timestamps=return_rawpoint_timestamps,\n",
    "        version=version,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091da9c9-4927-46f1-8848-f65ef0277ab0",
   "metadata": {},
   "source": [
    "The example stream has the following StatPoint from March 1, 2016 to May 31, 2016:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b11696b8-7c35-4cf6-b3b5-0d58a69d5b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'time': Timestamp('2016-03-01 00:00:00.008333+0000', tz='UTC'),\n",
       "  'min': 240.4445343017578,\n",
       "  'mean': 284.714006053764,\n",
       "  'max': 293.46502685546875,\n",
       "  'count': 949451443,\n",
       "  'stddev': 1.6748411051700447}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream.arrow_windows(start, end, width=end - start).to_pylist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37ce9c8-8261-4e68-b99d-701863199564",
   "metadata": {},
   "source": [
    "Set the min, mean to use in the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d60158c-e004-4b8b-b594-d6807acfe2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value = 240.4445343017578\n",
    "mean_value = 284.714006053764\n",
    "max_value = 293.46502685546875\n",
    "stddev_value = 1.6748411051700447"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02da2dd2-2be6-4e4d-ad61-7f1487d7533a",
   "metadata": {},
   "source": [
    "### Example: Finding the global minimum value from the above StatPoint window data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ac9f854-4a2f-4645-b0c3-ef3f6621bae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.01 ms, sys: 5.12 ms, total: 10.1 ms\n",
      "Wall time: 66.9 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartTime</th>\n",
       "      <th>EndTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-03-15 22:16:42.297966592+00:00</td>\n",
       "      <td>2016-03-15 22:17:16.657704960+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            StartTime                             EndTime\n",
       "0 2016-03-15 22:16:42.297966592+00:00 2016-03-15 22:17:16.657704960+00:00"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "equal_min_generator = search_timestamps_at_value(stream, start, end, value=min_value)\n",
    "timestamps_series = search_generator_to_dataframe(equal_min_generator)\n",
    "timestamps_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3133c84-e742-47b3-9490-933235d6a6ab",
   "metadata": {},
   "source": [
    "Because we are searching the global `mean` value of the Stream, and essentially touching all levels down to pointwidth of 36 which is the default value for `final_pw`, approximately 1.5 minutes. Let's change to 6 levels above `final_pw=42` to window of 1.22 hours.\n",
    "\n",
    "Note the time it took to ran the search, and see the timestamp gap in row 2-3:\n",
    "\n",
    "- Row 2's EndTime   : 2016-03-01 02:05:31.221811200+00:00\n",
    "- Row 3's StartTime : 2016-03-01 02:42:10.245066752+00:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad25d09c-da18-4655-ab5e-8af5802c638b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5822\n",
      "CPU times: user 897 ms, sys: 392 ms, total: 1.29 s\n",
      "Wall time: 7.81 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartTime</th>\n",
       "      <th>EndTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-03-01 00:15:34.152044544+00:00</td>\n",
       "      <td>2016-03-01 00:52:13.175300096+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-03-01 00:52:13.175300096+00:00</td>\n",
       "      <td>2016-03-01 01:28:52.198555648+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-03-01 01:28:52.198555648+00:00</td>\n",
       "      <td>2016-03-01 02:05:31.221811200+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-03-01 02:42:10.245066752+00:00</td>\n",
       "      <td>2016-03-01 03:18:49.268322304+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-03-01 04:32:07.314833408+00:00</td>\n",
       "      <td>2016-03-01 05:08:46.338088960+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            StartTime                             EndTime\n",
       "0 2016-03-01 00:15:34.152044544+00:00 2016-03-01 00:52:13.175300096+00:00\n",
       "1 2016-03-01 00:52:13.175300096+00:00 2016-03-01 01:28:52.198555648+00:00\n",
       "2 2016-03-01 01:28:52.198555648+00:00 2016-03-01 02:05:31.221811200+00:00\n",
       "3 2016-03-01 02:42:10.245066752+00:00 2016-03-01 03:18:49.268322304+00:00\n",
       "4 2016-03-01 04:32:07.314833408+00:00 2016-03-01 05:08:46.338088960+00:00"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "equal_mean_generator = search_timestamps_at_value(\n",
    "    stream, start, end, value=mean_value, final_pw=42  # ~1.22 hours\n",
    ")\n",
    "timestamps_series = search_generator_to_dataframe(equal_mean_generator)\n",
    "print(timestamps_series.size)\n",
    "timestamps_series.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbae2301-2cc8-4577-acfa-7b5fb2de7fd8",
   "metadata": {},
   "source": [
    "Because of StatPoints, the default behavior for all the search functions for `return_rawpoint_timestamps` is **`False`**.\n",
    "Let's change that to see the RawPoints timestamps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cd848ff-d1d0-41bb-ab2f-8eebff97a9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_rawpoint_timestamps = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b6bd1f5-f30d-404c-9564-8a84943ead8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.4 ms, sys: 1.81 ms, total: 26.2 ms\n",
      "Wall time: 58.9 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-03-15 22:16:58.574999+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Time\n",
       "0 2016-03-15 22:16:58.574999+00:00"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "equal_min_generator = search_timestamps_at_value(\n",
    "    stream,\n",
    "    start,\n",
    "    end,\n",
    "    value=min_value,\n",
    "    return_rawpoint_timestamps=return_rawpoint_timestamps,\n",
    ")\n",
    "timestamps_series = search_generator_to_dataframe(equal_min_generator)\n",
    "timestamps_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39a7117-c188-4948-a3b6-0d2d39363af2",
   "metadata": {},
   "source": [
    "To return rawpoints, let's make the value 2 stand-deviation above the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dede797-753c-4136-9317-21d5354bf35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "equal_generator = search_timestamps_at_value(\n",
    "    stream,\n",
    "    start,\n",
    "    end,\n",
    "    value=mean_value + 2 * stddev_value,\n",
    "    final_pw=42,  # ~1.22 hours\n",
    "    return_rawpoint_timestamps=return_rawpoint_timestamps,\n",
    ")\n",
    "timestamps_series = search_generator_to_dataframe(equal_generator)\n",
    "timestamps_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e43479b-ab37-4997-bff5-98ab8cac3d22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
